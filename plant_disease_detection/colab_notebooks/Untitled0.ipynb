{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1T5YEpY8BEJT2NoCIfkY491Beg612U2FJ","authorship_tag":"ABX9TyObh1+70stx/yAa8cW0yv3p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ZkocjvQjk_hc","executionInfo":{"status":"ok","timestamp":1720563616177,"user_tz":240,"elapsed":299,"user":{"displayName":"Labeba Tahsin","userId":"17320929968315191587"}}},"outputs":[],"source":["!cd /content"]},{"cell_type":"code","source":["!pip install git+https://github.com/facebookresearch/segment-anything.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-DP-viFlWmn","executionInfo":{"status":"ok","timestamp":1720563640864,"user_tz":240,"elapsed":13524,"user":{"displayName":"Labeba Tahsin","userId":"17320929968315191587"}},"outputId":"ea919e42-b742-4542-e00b-3c5c5da85fc9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-lxxiwevs\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-lxxiwevs\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: segment-anything\n","  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36590 sha256=63e502921bfbd3cbd7368cdd5bd5fd1ffc7724ff90019e10cab86e93cdcf7c91\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8lh49akq/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n","Successfully built segment-anything\n","Installing collected packages: segment-anything\n","Successfully installed segment-anything-1.0\n"]}]},{"cell_type":"code","source":["#=========================================================\n","#================== Create Annotation ====================\n","#=========================================================\n","\n","import os\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2\n","from segment_anything import sam_model_registry, SamPredictor\n","import json\n","import datetime\n","\n","# Define paths\n","path = \"train_test\"\n","image_dir = '/content/drive/MyDrive/plant_disease_detection/dataset/' + path\n","#mask_save_dir = '/content/drive/MyDrive/plant_disease_detection/dataset/masked_images_without_box/' + path\n","annotations_save_dir = '/content/drive/MyDrive/plant_disease_detection/dataset/annotations/plant_disease_detection_without_box'\n","\n","# Ensure the mask save directory exists\n","#os.makedirs(mask_save_dir, exist_ok=True)\n","os.makedirs(annotations_save_dir, exist_ok=True)\n","\n","# Load the SAM model\n","sam_checkpoint = \"/content/drive/MyDrive/plant_disease_detection/models/sam_vit_h_4b8939.pth\"\n","model_type = \"vit_h\"\n","device = \"cuda\"\n","\n","sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","sam.to(device=device)\n","\n","predictor = SamPredictor(sam)\n","\n","# Initialize COCO Panoptic annotation format\n","coco_output = {\n","    \"info\": {\n","        \"description\": \"Plant Disease Detection Dataset\",\n","        \"version\": \"1.0\",\n","        \"year\": datetime.datetime.now().year,\n","        \"contributor\": \"Labeba Tahsin\",\n","        \"date_created\": datetime.datetime.now().isoformat()\n","    },\n","    \"licenses\": [],\n","    \"images\": [],\n","    \"annotations\": [],\n","    \"categories\": []\n","}\n","\n","# Collect category information from subfolder names\n","categories = []\n","category_id_mapping = {}\n","category_id = 1\n","for subdir in os.listdir(image_dir):\n","    if os.path.isdir(os.path.join(image_dir, subdir)):\n","        category_info = {\n","            \"id\": category_id,\n","            \"name\": subdir,\n","        }\n","        categories.append(category_info)\n","        category_id_mapping[subdir] = category_id\n","        category_id += 1\n","\n","coco_output[\"categories\"] = categories\n","\n","annotation_id = 1\n","\n","# Iterate over all subfolders and images in the directory\n","for root, dirs, files in os.walk(image_dir):\n","    for image_file in files:\n","        if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n","            try:\n","                # Load the image\n","                image_path = os.path.join(root, image_file)\n","                image = cv2.imread(image_path)\n","                if image is None:\n","                    print(f\"Failed to load image {image_file}\")\n","                    continue\n","                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","                height, width, _ = image_rgb.shape\n","\n","                # Update file name with full path for COCO annotation\n","                relative_path = os.path.relpath(root, image_dir)\n","                full_image_path = os.path.join('/content/drive/MyDrive/plant_disease_detection/dataset', path, relative_path, image_file)\n","\n","                # Add image info to COCO\n","                image_info = {\n","                    \"id\": annotation_id,\n","                    \"file_name\": full_image_path,\n","                    \"height\": height,\n","                    \"width\": width\n","                }\n","                coco_output[\"images\"].append(image_info)\n","\n","                # Set the image for prediction\n","                predictor.set_image(image_rgb)\n","\n","                # Define central point\n","                central_point = np.array([width // 2, height // 2])\n","                input_points = np.vstack([central_point])\n","                input_labels = np.ones(input_points.shape[0])\n","                input_box = np.array([8, 8, width - 8, height - 8])\n","\n","                # Predict masks using the input points\n","                masks, scores, logits = predictor.predict(\n","                    point_coords=input_points,\n","                    point_labels=input_labels,\n","                    box=input_box,\n","                    multimask_output=True,\n","                )\n","\n","                # Identify the mask with the highest score\n","                best_mask_idx = np.argmax(scores)\n","                best_mask = masks[best_mask_idx]\n","                best_score = scores[best_mask_idx]\n","\n","                # Draw the mask on the overlay\n","                overlay = image_rgb.copy()\n","                color = np.array([255 / 255, 20 / 255, 147 / 255, 0.6])  # Pinkish color\n","                h, w = best_mask.shape[-2:]\n","                mask_image = best_mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","                overlay = cv2.addWeighted(overlay, 0.7, (mask_image[:, :, :3] * 255).astype(np.uint8), 0.3, 0)\n","\n","                # Draw the box on the overlay (Optional, can be removed)\n","                x0, y0, x1, y1 = input_box\n","                # cv2.rectangle(overlay, (x0, y0), (x1, y1), (0, 255, 0), 1)  # Lawngreen color\n","\n","                # Create corresponding subfolder in the mask save directory\n","                #save_subdir = os.path.join(mask_save_dir, relative_path)\n","                #os.makedirs(save_subdir, exist_ok=True)\n","\n","                # Save the overlay image\n","                # overlay_path = os.path.join(save_subdir, f\"overlay_{image_file}\")\n","                # cv2.imwrite(overlay_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n","\n","                # Prepare annotation for COCO\n","                segmentation = np.zeros((height, width), dtype=np.uint16)\n","                segmentation[best_mask] = annotation_id\n","\n","                # Get category ID based on folder name\n","                category_name = os.path.basename(root)\n","                category_id = category_id_mapping[category_name]\n","\n","                annotation_info = {\n","                    \"id\": annotation_id,\n","                    \"image_id\": annotation_id,\n","                    \"category_id\": category_id,\n","                    \"segmentation\": segmentation.tolist(),\n","                    \"area\": int(np.sum(best_mask)),\n","                    \"iscrowd\": 0\n","                }\n","                coco_output[\"annotations\"].append(annotation_info)\n","\n","                annotation_id += 1\n","\n","                print(f\"Processed {image_file} - Best mask score: {best_score:.3f}\")\n","            except Exception as e:\n","                print(f\"Failed to process {image_file}: {str(e)}\")\n","\n","# Save COCO annotations to a file\n","with open(os.path.join(annotations_save_dir, f\"coco_panoptic_{path}.json\"), 'w') as json_file:\n","    json.dump(coco_output, json_file, indent=4)\n","\n","print(\"Processing complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gM7zf9MBlfA_","executionInfo":{"status":"ok","timestamp":1720564049648,"user_tz":240,"elapsed":26627,"user":{"displayName":"Labeba Tahsin","userId":"17320929968315191587"}},"outputId":"05f70184-056b-4a8c-ffa1-b0022c48d9f7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed fdec728a-c3e5-478d-9e14-ac1a717d5ffc___Crnl_L.Mold 9045_flipTB.JPG - Best mask score: 0.999\n","Processed fd2cc427-8f4c-4551-96db-bd5d53974039___Crnl_L.Mold 6684.JPG - Best mask score: 0.995\n","Processed fe00923d-7acb-4a3b-9104-e2d429181e5d___Crnl_L.Mold 6822_flipTB.JPG - Best mask score: 1.018\n","Processed fc3b00ae-34b4-41f4-9122-5649f1aca3d8___Crnl_L.Mold 6687_flipTB.JPG - Best mask score: 1.012\n","Processed 1692055a-2fc8-4680-b8fe-32916f040b6f___Crnl_L.Mold 6843.JPG - Best mask score: 1.017\n","Processed Copy of 0a2de4c5-d688-4f9d-9107-ace1d281c307___Com.G_TgS_FL 7941_180deg.JPG - Best mask score: 1.008\n","Processing complete.\n"]}]}]}